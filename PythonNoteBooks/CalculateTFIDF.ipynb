{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from time import time\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words and weights: \n",
      "\n",
      "['?', 'be', 'the', 'what', 'do', 'a', 'i', 'how', 'to', 'in', 'of', 'and', 'can', 'for', ',', 'you', 'why', 'it', 'my', 'best', 'have', 'on', 'is', 'get', '.', 'or', 'which', 'if', 'some', 'that', 'with', 'should', \"'s\", 'an', 'from', 'your', 'good', 'india', 'will', 'make', 'like', 'people', 'when', 'who', ')']\n",
      "\n",
      "Least common words and weights: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.708399\n",
      "1      0.480824\n",
      "2      0.000000\n",
      "3      1.000000\n",
      "4      0.589391\n",
      "5      0.935088\n",
      "6      0.749895\n",
      "7      0.291571\n",
      "8      0.821795\n",
      "9      0.955675\n",
      "10     0.211453\n",
      "11     0.502059\n",
      "12     1.000000\n",
      "13     0.665331\n",
      "14     0.248175\n",
      "15     0.094984\n",
      "16     0.545955\n",
      "17     0.040958\n",
      "18     0.634754\n",
      "19     0.000000\n",
      "20     1.000000\n",
      "21     0.721105\n",
      "22     0.506856\n",
      "23     0.547938\n",
      "24     0.822837\n",
      "25     0.626195\n",
      "26     0.453218\n",
      "27     0.000000\n",
      "28     0.364005\n",
      "29     0.189823\n",
      "         ...   \n",
      "970    0.342787\n",
      "971    0.939002\n",
      "972    0.700376\n",
      "973    1.000000\n",
      "974    0.000000\n",
      "975    0.124602\n",
      "976    0.272418\n",
      "977    0.674846\n",
      "978    0.421901\n",
      "979    0.000000\n",
      "980    0.355868\n",
      "981    0.196049\n",
      "982    0.635575\n",
      "983    0.718850\n",
      "984    0.269952\n",
      "985    0.000000\n",
      "986    0.698308\n",
      "987    0.480852\n",
      "988    0.544421\n",
      "989    0.524010\n",
      "990    0.296819\n",
      "991    0.509526\n",
      "992    0.064402\n",
      "993    0.537203\n",
      "994    0.261114\n",
      "995    0.613320\n",
      "996    0.596079\n",
      "997    0.615850\n",
      "998    0.402284\n",
      "999    0.832747\n",
      "Length: 1000, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403287 entries, 0 to 403286\n",
      "Data columns (total 11 columns):\n",
      "id                      403287 non-null int64\n",
      "qid1                    403287 non-null int64\n",
      "qid2                    403287 non-null int64\n",
      "question1               403287 non-null object\n",
      "question2               403287 non-null object\n",
      "is_duplicate            403287 non-null int64\n",
      "lem_question1           403287 non-null object\n",
      "lem_question2           403287 non-null object\n",
      "tfidf_word_match        403264 non-null float64\n",
      "lem_tfidf_word_match    403271 non-null float64\n",
      "intersection_count      403287 non-null int64\n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 33.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class CalculateTFIDF:\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        \n",
    "        trainData = pd.read_csv('../LematizedFiles/trainlem.csv', engine='python')\n",
    "        testData = pd.read_csv('../LematizedFiles/testlem.csv', engine='python')\n",
    "\n",
    "        def get_weight(count, eps=10000, min_count=2):\n",
    "            if count < min_count:\n",
    "                return 0\n",
    "            else:\n",
    "                return 1 / (count + eps)\n",
    "\n",
    "\n",
    "        eps = 5000 \n",
    "        words = (\" \".join(trainData['lem_question1'])).lower().split()\n",
    "        counts = Counter(words)\n",
    "        words2 = (\" \".join(trainData['lem_question2'])).lower().split()\n",
    "        counts2 = Counter(words2)\n",
    "        totalcount = counts + counts2\n",
    "        weights = {word: get_weight(count) for word, count in totalcount.items()}\n",
    "\n",
    "        print('Most common words and weights: \\n')\n",
    "        check_list = sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:45]\n",
    "        stops = [i[0] for i in check_list]\n",
    "        print(stops)\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nLeast common words and weights: ')\n",
    "        (sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "        \n",
    "        \n",
    "        def tfidf_word_match_share(row):\n",
    "            q1words = {}\n",
    "            q2words = {}\n",
    "            for word in str(row['lem_question1']).lower().split():\n",
    "                if word not in stops:\n",
    "                    q1words[word] = 1\n",
    "            for word in str(row['lem_question2']).lower().split():\n",
    "                if word not in stops:\n",
    "                    q2words[word] = 1\n",
    "            if len(q1words) == 0 or len(q2words) == 0:\n",
    "                # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "                return 0\n",
    "\n",
    "            shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "            total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "\n",
    "            R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "            return R\n",
    "        \n",
    "        \n",
    "        tfidf_train_word_match = trainData.apply(tfidf_word_match_share, axis=1, raw=True)\n",
    "        tfidf_test_word_match = testData.apply(tfidf_word_match_share, axis=1, raw=True)\n",
    "        \n",
    "        \n",
    "        trainData['lem_tfidf_word_match'] = tfidf_train_word_match\n",
    "        testData['lem_tfidf_word_match'] = tfidf_test_word_match\n",
    "\n",
    "        print(tfidf_test_word_match)\n",
    "\n",
    "        print(trainData.info())\n",
    "\n",
    "\n",
    "        trainData.to_csv('../LematizedFiles/trainlem.csv', index = False)\n",
    "        testData.to_csv('../LematizedFiles/testlem.csv', index = False)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
