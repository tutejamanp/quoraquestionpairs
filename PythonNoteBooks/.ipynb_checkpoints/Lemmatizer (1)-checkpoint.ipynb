{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from time import time\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1acd6fd1c10c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lem_question1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mwords2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lem_question2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainData' is not defined"
     ]
    }
   ],
   "source": [
    "trainData = pd.read_csv('../LemmatizedFiles/train.csv')\n",
    "testData = pd.read_csv('../LemmatizedFiles/test.csv')\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "\n",
    "eps = 5000 \n",
    "words = (\" \".join(trainData['lem_question1'])).lower().split()\n",
    "counts = Counter(words)\n",
    "words2 = (\" \".join(trainData['lem_question2'])).lower().split()\n",
    "counts2 = Counter(words2)\n",
    "totalcount = counts + counts2\n",
    "weights = {word: get_weight(count) for word, count in totalcount.items()}\n",
    "\n",
    "print('Most common words and weights: \\n')\n",
    "check_list = sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:45]\n",
    "stops = [i[0] for i in check_list]\n",
    "print(stops)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nLeast common words and weights: ')\n",
    "(sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in str(row['lem_question1']).lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in str(row['lem_question2']).lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    \n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav Joshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "tfidf_train_word_match = trainData.apply(tfidf_word_match_share, axis=1, raw=True)\n",
    "tfidf_test_word_match = testData.apply(tfidf_word_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.000000\n",
       "1         0.809108\n",
       "2         0.487779\n",
       "3         0.406075\n",
       "4         0.000000\n",
       "5         0.000000\n",
       "6         0.520428\n",
       "7         0.413904\n",
       "8         0.000000\n",
       "9         0.575615\n",
       "10        0.375844\n",
       "11        1.000000\n",
       "12        0.888173\n",
       "13        1.000000\n",
       "14        0.303613\n",
       "15        0.341740\n",
       "16        0.791272\n",
       "17        0.375947\n",
       "18        0.307221\n",
       "19        0.725873\n",
       "20        0.571126\n",
       "21        0.603648\n",
       "22        0.208834\n",
       "23        0.584276\n",
       "24        1.000000\n",
       "25        0.294893\n",
       "26        0.496695\n",
       "27        0.247766\n",
       "28        0.345142\n",
       "29        0.195431\n",
       "            ...   \n",
       "403257    0.334837\n",
       "403258    0.745138\n",
       "403259    0.316876\n",
       "403260    0.502385\n",
       "403261    0.000000\n",
       "403262    0.717776\n",
       "403263    1.000000\n",
       "403264    0.467715\n",
       "403265    0.813055\n",
       "403266    0.160342\n",
       "403267    0.398793\n",
       "403268    0.409497\n",
       "403269    0.218338\n",
       "403270    0.451940\n",
       "403271    0.621571\n",
       "403272    0.887698\n",
       "403273    0.380717\n",
       "403274    0.412004\n",
       "403275    0.799554\n",
       "403276    0.877082\n",
       "403277    0.387166\n",
       "403278    0.351329\n",
       "403279    1.000000\n",
       "403280    0.681661\n",
       "403281    0.237071\n",
       "403282    0.686183\n",
       "403283    0.765238\n",
       "403284    0.508936\n",
       "403285    0.897116\n",
       "403286    0.626273\n",
       "Length: 403287, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_word_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.708399\n",
      "1      0.480824\n",
      "2      0.000000\n",
      "3      1.000000\n",
      "4      0.589391\n",
      "5      0.935088\n",
      "6      0.749895\n",
      "7      0.291571\n",
      "8      0.821795\n",
      "9      0.955675\n",
      "10     0.211453\n",
      "11     0.502059\n",
      "12     1.000000\n",
      "13     0.665331\n",
      "14     0.248175\n",
      "15     0.094984\n",
      "16     0.545955\n",
      "17     0.040958\n",
      "18     0.634754\n",
      "19     0.000000\n",
      "20     1.000000\n",
      "21     0.721105\n",
      "22     0.506856\n",
      "23     0.547938\n",
      "24     0.822837\n",
      "25     0.626195\n",
      "26     0.453218\n",
      "27     0.000000\n",
      "28     0.364005\n",
      "29     0.189823\n",
      "         ...   \n",
      "970    0.342787\n",
      "971    0.939002\n",
      "972    0.700376\n",
      "973    1.000000\n",
      "974    0.000000\n",
      "975    0.124602\n",
      "976    0.272418\n",
      "977    0.674846\n",
      "978    0.421901\n",
      "979    0.000000\n",
      "980    0.355868\n",
      "981    0.196049\n",
      "982    0.635575\n",
      "983    0.718850\n",
      "984    0.269952\n",
      "985    0.000000\n",
      "986    0.698308\n",
      "987    0.480852\n",
      "988    0.544421\n",
      "989    0.524010\n",
      "990    0.296819\n",
      "991    0.509526\n",
      "992    0.064402\n",
      "993    0.537203\n",
      "994    0.261114\n",
      "995    0.613320\n",
      "996    0.596079\n",
      "997    0.615850\n",
      "998    0.402284\n",
      "999    0.832747\n",
      "Length: 1000, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 403287 entries, 0 to 403286\n",
      "Data columns (total 10 columns):\n",
      "id                      403287 non-null int64\n",
      "qid1                    403287 non-null int64\n",
      "qid2                    403287 non-null int64\n",
      "question1               403287 non-null object\n",
      "question2               403287 non-null object\n",
      "is_duplicate            403287 non-null int64\n",
      "lem_question1           403287 non-null object\n",
      "lem_question2           403287 non-null object\n",
      "tfidf_word_match        403264 non-null float64\n",
      "lem_tfidf_word_match    403271 non-null float64\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 43.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trainData['lem_tfidf_word_match'] = tfidf_train_word_match\n",
    "testData['lem_tfidf_word_match'] = tfidf_test_word_match\n",
    "\n",
    "print(tfidf_test_word_match)\n",
    "\n",
    "print(trainData.info())\n",
    "\n",
    "\n",
    "trainData.to_csv('lemmatizedTrainData1.csv', index = False)\n",
    "testData.to_csv('lemmatizedTestData1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
